# 6.管理字符集和编码

从前有 EBCDIC 和 ASCII。事实上，它从来没有那么简单，只是随着时间的推移变得更加复杂。地平线上有光，但一些人估计，我们可能需要 50 年才能在这里生活在日光下！

早期的计算机是在说英语的美国、英国和澳大利亚发展起来的。因此，人们对正在使用的语言和字符集做出了假设。基本上，使用拉丁字母，加上数字，标点符号，和一些其他的。然后使用 ASCII 或 EBCDIC 将这些编码成字节。

字符处理机制基于此:文本文件和 I/O 由一系列字节组成，每个字节代表一个字符。字符串比较可以通过匹配相应的字节来完成；从大写到小写的转换可以通过映射单个字节来完成，等等。

世界上大约有 6500 种口语(其中 850 种在巴布亚新几内亚！).少数语言使用“英语”字符，但大多数不使用。像法语这样的罗马语言在不同的字符上有装饰，所以你可以用两个不同重音的元音写“j'ai arrêté”。同样，日耳曼语也有额外的字符，如“σ”。甚至英国英语也有不在标准 ASCII 码集中的字符:英镑符号“”和最近的欧元“€”。

但是这个世界并不局限于拉丁字母的变体。泰国有自己的字母表，单词看起来像这样:“ภาษาไทย".还有很多其他的字母，日本甚至有两个，平假名和片假名。

也有象形文字语言，比如中文，你可以在上面写字百度一下,你就知道".

从技术角度来看，如果全世界都使用 ASCII 就好了。然而，趋势是相反的，越来越多的用户要求软件使用他们熟悉的语言。如果你开发一个可以在不同国家运行的应用程序，那么用户会要求它使用他们自己的语言。在分布式系统中，期望不同语言和字符的用户可以使用系统的不同组件。

国际化(i18n)是您如何编写应用程序，以便它们可以处理各种语言和文化。本地化(l10n)是针对特定文化群体定制您的国际化应用程序的过程。

i18n 和 l10n 本身就是大话题。例如，它们涵盖了颜色等问题:虽然白色在西方文化中意味着“纯洁”，但它对中国人来说意味着“死亡”，对埃及人来说意味着“快乐”。在这一章中，我们只看字符处理的问题。

## 定义

很重要的一点是要注意你所说的是文本处理系统的哪一部分。这里有一组被证明有用的定义。

### 性格；角色；字母

字符是“大致对应于自然语言的字形(书面符号)的信息单元，如字母、数字或标点符号”(维基百科)。字符是“书面语言中具有语义价值的最小组成部分”(Unicode)。这包括字母，如“a”和“à”(或任何其他语言的字母)，数字，如“2”，标点符号，如“，”和各种符号，如英国英镑货币符号“”。

一个字符是任何实际符号的某种抽象:字符“a”对于任何书写的“a”就像柏拉图的圆圈对于任何实际的圆圈一样。字符的概念还包括控制字符，它不对应于自然语言符号，而是对应于用于处理语言文本的其他信息。

一个角色没有任何特定的外貌，尽管我们用外貌来帮助识别角色。然而，即使是外观也可能必须在一个上下文中理解:在数学中，如果你看到符号π (pi ),它是圆周与半径之比的字符，而如果你正在阅读希腊文本，它是字母表的第 16 个字母:“ρρoσ”是希腊单词“with ”,与 3.14159 无关。

### 字符集/字符集

字符集是一组不同的字符，如拉丁字母。不假定特定的顺序。在英语中，虽然我们说“a”在字母表中比“z”早，但我们不会说“a”比“z”少。“电话簿”的排序将“麦克菲”放在“麦克雷”之前，这表明“字母排序”对角色来说并不重要。

剧目指定了角色的名字，通常还有角色的样片。例如，字母“a”可能看起来像“a”、“a”或“a”。但这并不强迫它们看起来像那样——它们只是样品。剧目可能会作出区分，如大写和小写，以便“A”和“A”是不同的。但它可能认为它们是相同的，只是样品外观不同。(就像一些编程语言将大写和小写视为不同一样——Go——但一些不这样——Basic。).另一方面，一个汇编可能包含具有相同样本外观的不同字符:一个希腊数学家的汇编可能有两个具有π外观的不同字符。这也称为非编码字符集。

### 字符二进制码

字符代码是从字符到整数的映射。字符集的映射也称为编码字符集或代码集。这种映射中每个字符的值通常称为代码点。ASCII 是一种代码集。“A”的码位是 97，而“A”的码位是 65(十进制)。

字符代码仍然是一个抽象概念。它还不是我们将在文本文件或 TCP 包中看到的。然而，它越来越接近了，因为它提供了从面向人的概念到数字概念的映射。

### 字符编码

为了交流或存储一个字符，你需要以某种方式对它进行编码。要传输一个字符串，需要对字符串中的所有字符进行编码。任何代码集都有许多可能的编码。

例如，7 位 ASCII 码位可以编码为 8 位字节(一个八位字节)。因此，ASCII“A”(代码点为 65)被编码为 8 位二进制八位数 01000001。然而，另一种不同的编码方式是将高位用于奇偶校验。例如，对于奇数奇偶校验，ASCII“A”将是八位字节 11000001。一些协议如 Sun 的 XDR 使用 32 位字长编码。ASCII“A”将被编码为 0000000000000000000000000001000001。

字符编码是我们在编程层面的功能。我们的程序处理编码字符。显然，我们是处理带或不带奇偶校验的 8 位字符，还是处理 32 位字符是有区别的。

编码扩展到字符串。“ABC”的字长偶校验编码可能是 10000000(高位字节中的奇偶校验位)0100000011(C)01000010(B)01000001(低位字节中的 A)。关于编码重要性的评论同样适用于字符串，只是规则可能有所不同。

### 传输编码

字符编码足以在单个应用程序中处理字符。然而，一旦你开始在应用程序之间发送文本，那么就有一个更进一步的问题，如何将字节、缩写或单词放到网络上。编码可以基于节省空间和带宽的技术，如压缩文本。或者可以简化为 7 位格式，以允许奇偶校验位，例如 base64。

如果我们知道字符和传输编码，那么管理字符和字符串就是编程的问题了。如果我们不知道字符或传输编码，那么如何处理任何特定的字符串就只能靠猜测了。文件没有约定来表示字符编码。

然而，在通过互联网传输的文本中有一个信令编码的惯例。很简单:文本消息的报头包含编码信息。例如，HTTP 头可以包含如下行:

```go
Content-Type: text/html; charset=ISO-8859-4
Content-Encoding: gzip

```

这表明字符集是 ISO 8859-4(对应于欧洲的某些国家)的默认编码，但是后来被压缩了。第二部分—内容编码—我们称之为“传输编码”(IETF RFC 2130)。

但是你如何阅读这些信息呢？不是被编码了吗？我们不是有一个先有鸡还是先有蛋的局面吗？不，约定是这样的信息以 ASCII(准确地说是 US ASCII)给出，这样程序可以读取文件头，然后为文档的其余部分调整它的编码。

## 美国信息交换标准代码

ASCII 包含英文字符、数字、标点符号和一些控制字符。这个熟悉的表格给出了 ASCII 的代码点:

```go
Oct   Dec   Hex   Char           Oct   Dec   Hex   Char
------------------------------------------------------------
000   0     00    NUL '¥0'       100   64    40    @
001   1     01    SOH            101   65    41    A
002   2     02    STX            102   66    42    B
003   3     03    ETX            103   67    43    C
004   4     04    EOT            104   68    44    D
005   5     05    ENQ            105   69    45    E
006   6     06    ACK            106   70    46    F
007   7     07    BEL '\a'       107   71    47    G
010   8     08    BS  '\b'       110   72    48    H
011   9     09    HT  '\t'       111   73    49    I
012   10    0A    LF  '\n'       112   74    4A    J
013   11    0B    VT  '\v'       113   75    4B    K
014   12    0C    FF  '\f'       114   76    4C    L
015   13    0D    CR  '\r'       115   77    4D    M
016   14    0E    SO             116   78    4E    N
017   15    0F    SI             117   79    4F    O
020   16    10    DLE            120   80    50    P
021   17    11    DC1            121   81    51    Q
022   18    12    DC2            122   82    52    R
023   19    13    DC3            123   83    53    S
024   20    14    DC4            124   84    54    T
025   21    15    NAK            125   85    55    U
026   22    16    SYN            126   86    56    V
027   23    17    ETB            127   87    57    W
030   24    18    CAN            130   88    58    X
031   25    19    EM             131   89    59    Y
032   26    1A    SUB            132   90    5A    Z
033   27    1B    ESC            133   91    5B    [
034   28    1C    FS             134   92    5C    \
035   29    1D    GS             135   93    5D    ]
036   30    1E    RS             136   94    5E    ^
037   31    1F    US             137   95    5F    _
040   32    20    SPACE          140   96    60    `
041   33    21    !              141   97    61    a
042   34    22    "              142   98    62    b
043   35    23    #              143   99    63    c
044   36    24    $              144   100   64    d
045   37    25    %              145   101   65    e
046   38    26    &              146   102   66    f
047   39    27    '              147   103   67    g
050   40    28    (              150   104   68    h
051   41    29    )              151   105   69    i
052   42    2A    *              152   106   6A    j
053   43    2B    +              153   107   6B    k
054   44    2C    ,              154   108   6C    l
055   45    2D    -              155   109   6D    m
056   46    2E    .              156   110   6E    n
057   47    2F    /              157   111   6F    o
060   48    30    0              160   112   70    p
061   49    31    1              161   113   71    q
062   50    32    2              162   114   72    r
063   51    33    3              163   115   73    s
064   52    34    4              164   116   74    t
065   53    35    5              165   117   75    u
066   54    36    6              166   118   76    v
067   55    37    7              167   119   77    w
070   56    38    8              170   120   78    x
071   57    39    9              171   121   79    y
072   58    3A    :              172   122   7A    z
073   59    3B    ;              173   123   7B    {
074   60    3C    <              174   124   7C    |
075   61    3D    =              175   125   7D    }
076   62    3E    >              176   126   7E    ∼
077   63    3F    ?              177   127   7F    DEL

```

(一个有趣的四列版本在罗比的垃圾，四列 ASCII 在 [`https://garbagecollected.org/2017/01/31/four-column-ascii/`](https://garbagecollected.org/2017/01/31/four-column-ascii/) 。)

ASCII 最常见的编码使用代码点作为 7 位字节，因此例如“A”的编码是 65。

这套其实是美国 ASCII。由于欧洲人对重音字符的需求，一些标点符号被省略以形成最小集合，ISO 646，而有适合欧洲字符的“国家变体”。朱卡·科尔佩拉的网站 [`http://www.cs.tut.fi/~jkorpela/chars.html`](http://www.cs.tut.fi/~jkorpela/chars.html) 为感兴趣的人提供了更多信息。但是，对于本书中的工作，您不需要这些变体。

## ISO 8859

八位字节现在是字节的标准大小。这为 ASCII 扩展提供了 128 个额外的代码点。许多不同的代码集，以捕捉欧洲各种语言子集的剧目是 ISO 8859 系列。ISO 8859-1 也被称为拉丁语-1，涵盖西欧的许多语言，而本系列中的其他语言涵盖欧洲其他地区，甚至希伯来语、阿拉伯语和泰语。例如，ISO 8859-5 包括俄国等国家的西里尔字符，而 ISO 8859-8 包括希伯来字母。

这些字符集的标准编码是使用它们的码位作为 8 位值。例如，ISO 8859-1 的字符“Á”的代码点为 193，编码为 193。所有 ISO 8859 序列的底部 128 个值都与 ASCII 相同，因此所有这些集合中的 ASCII 字符都是相同的。

用来推荐 ISO 8859-1 字符集的 HTML 规范。HTML 3.2 是最后一个这样做的，之后 HTML 4.0 推荐了 Unicode。2008 年，谷歌估计它看到的网页中，大约 20%仍然是 ISO 8859 格式，20%仍然是 ASCII 格式(见[`http://googleblog.blogspot.com/2010/01/unicode-nearing-50-of-web.html`](http://googleblog.blogspot.com/2010/01/unicode-nearing-50-of-web.html)“Unicode 接近 50%的网页”)。更多背景信息参见 [`http://pinyin.info/news/2015/utf-8-unicode-vs-other-encodings-over-time/`](http://pinyin.info/news/2015/utf-8-unicode-vs-other-encodings-over-time/) 和 [`https://w3techs.com/technologies/history_overview/character_encoding`](https://w3techs.com/technologies/history_overview/character_encoding) 。

## 统一码

ASCII 和 ISO 8859 都没有涵盖基于象形文字的语言。据估计，中文大约有 20，000 个独立的汉字，其中大约有 5，000 个是通用的。这些需要不止一个字节，通常使用两个字节。这种双字节字符集有很多:中文的 Big5、EUC-TW、GB2312 和 GBK/GBX，日文的 JIS X 0208 等等。这些编码通常不相互兼容。

Unicode 是一种兼容的标准字符集，旨在涵盖所有正在使用的主要字符集。它包括欧洲、亚洲、印度等等。现在已经到了 9.0 版本，有 128，172 个字符。代码点的数量现在超过了 65，536。这比 2^16.还多这对字符编码有影响。

前 256 个码位对应于 ISO 8859-1，前 128 个是美国 ASCII 码。这样就有了与这些主要字符集的向后兼容性，因为 ISO 8859-1 和 ASCII 的码位在 Unicode 中完全相同。对于其他字符集来说，情况就不一样了:例如，虽然大部分 Big5 字符也是 Unicode 的，但是代码点却不一样。网站 [`http://moztw.org/docs/big5/table/unicode1.1-obsolete.txt`](http://moztw.org/docs/big5/table/unicode1.1-obsolete.txt) 包含一个从 Big5 到 Unicode 的(大)表映射的例子。

要在计算机系统中表示 Unicode 字符，必须使用编码。编码 UCS 是使用 Unicode 字符的码位值的双字节编码。但是，由于现在 Unicode 中的字符太多，无法全部放入 2 个字节，这种编码已经过时，不再使用。相反，有:

*   UTF-32 是一种 4 字节编码，但并不常用，HTML 5 明确警告不要使用它。
*   UTF-16 将最常见的字符编码成 2 个字节，另外 2 个字节用于“溢出”，ASCII 和 ISO 8859-1 具有通常的值。
*   UTF-8 使用每个字符 1 到 4 个字节，ASCII 具有通常的值(但不是 ISO 8859-1)。
*   UTF-7 有时会使用，但并不常见。

## UTF 8 号，走，还有符文

UTF 8 是最常用的编码。谷歌估计，在 2008 年，它看到的 50%的网页是用 UTF-8 编码的，而且这个比例还在增加。ASCII 集在 UTF-8 中具有相同的编码值，因此 UTF-8 阅读器可以阅读仅由 ASCII 字符组成的文本以及完整 Unicode 集中的文本。

Go 在其字符串中使用 UTF-8 编码的字符。每个字符的类型都是`rune`。这是 int32 的别名。在 UTF-8 编码中，一个 Unicode 字符最多可以有 4 个字节，因此需要 4 个字节来表示所有字符。就字符而言，字符串是一个符文数组，每个符文使用 1、2 或 4 个字节。

字符串也是一个字节数组，但是你必须小心:只有对于 ASCII 子集，一个字节等于一个字符。所有其他字符占用 2、3 或 4 个字节。这意味着字符(符文)中字符串的长度通常与其字节数组的长度不同。只有当字符串仅由 ASCII 字符组成时，它们才相等。

下面的程序片段说明了这一点。如果您获取一个 UTF-8 字符串并测试它的长度，您将获得底层字节数组的长度。但是如果你将字符串转换成一个符文数组`[]rune`,那么你会得到一个 Unicode 码位数组，它通常是字符数:

```go
str := "百度一下, 你就知道"

println("String length", len([]rune(str)))
println("Byte length", len(str))

prints
String length 9
Byte length 27

```

Go博客(见 [`https://blog.golang.org/strings`](https://blog.golang.org/strings) )给出了关于琴弦和符文更详细的解释。

### UTF-8 客户端和服务器

可能令人惊讶的是，您不需要做任何特殊的事情来处理客户端或服务器中的 UTF-8 文本。Go 中 UTF-8 字符串的底层数据类型是一个字节数组，正如我们刚刚看到的，Go 会根据需要将字符串编码成 1、2、3 或 4 个字节。字符串的长度就是字节数组的长度，所以你可以通过写字节数组来写任何 UTF-8 字符串。

类似地，要读取一个字符串，只需读入一个字节数组，然后使用`string([]byte)`将该数组转换为一个字符串。如果 Go 不能正确地将字节解码成 Unicode 字符，那么它给出 Unicode 替换字符`\uFFFD`。结果字节数组的长度是字符串合法部分的长度。

因此，前几章给出的客户机和服务器可以很好地处理 UTF-8 编码的文本。

### ASCII 客户端和服务器

ASCII 字符在 ASCII 和 UTF-8 中具有相同的编码。所以普通的 UTF-8 字符处理对 ASCII 字符来说很好。不需要进行特殊处理。

## UTF-16 和 Go

UTF-16 处理短 16 位无符号整数数组。utf16 软件包就是为管理这样的数组而设计的。要将一个普通的 Go 字符串(即 UTF-8 字符串)转换成 UTF-16，首先通过将它强制转换成一个`[]rune`来提取代码点，然后使用`utf16.Encode`来产生一个 uint16 类型的数组。

类似地，要将一个无符号的短 UTF-16 值数组解码成一个 Go 字符串，可以使用`utf16.Decode`将其转换成类型为`[]rune`的码位，然后转换成一个字符串。以下代码片段说明了这一点:

```go
str := "百度一下, 你就知道"

runes := utf16.Encode([]rune(str))
ints := utf16.Decode(runes)

str = string(ints)

```

这些类型转换需要由客户机或服务器适当地应用，以读取和写入 16 位短整数，如下所示。

### 小端和大端

可惜 UTF-16 背后潜伏着一个小恶魔。它基本上是将字符编码成 16 位短整数。大问题是:对于每个 short，如何写成两个字节？先顶一个，还是先顶一个第二？只要接收方使用与发送方相同的约定，任何一种方式都可以。

Unicode 通过一种称为 BOM(字节顺序标记)的特殊字符解决了这个问题。这是一个零宽度的非打印字符，所以你永远不会在文本中看到它。但是它的值`0xfffe`是这样选择的，这样您就可以知道字节顺序:

*   在大端系统中，它是 FF FE
*   在小端系统中，它是 FE FF

文本有时会将 BOM 作为文本中的第一个字符。然后，读取器可以检查这两个字节，以确定使用了什么字节序。

### UTF-16 客户端和服务器

使用 BOM 约定，您可以编写一个服务器，预先计划一个 BOM，并以 UTF-16 格式编写一个字符串作为`UTF16Server.go`:

```go
/* UTF16 Server
 */
package main

import (
        "fmt"
        "net"
        "os"
        "unicode/utf16"
)

const BOM = '\ufffe'

func main() {

        service := "0.0.0.0:1210"
        tcpAddr, err := net.ResolveTCPAddr("tcp", service)
        checkError(err)

        listener, err := net.ListenTCP("tcp", tcpAddr)
        checkError(err)

        for {
                conn, err := listener.Accept()
                if err != nil {
                        continue
                }

                str := "j'ai arrÃªtÃ©"
                shorts := utf16.Encode([]rune(str))
                writeShorts(conn, shorts)

                conn.Close() // we're finished
        }
}

func writeShorts(conn net.Conn, shorts []uint16) {
        var bytes [2]byte

        // send the BOM as first two bytes
        bytes[0] = BOM >> 8
        bytes[1] = BOM & 255
        _, err := conn.Write(bytes[0:])
        if err != nil {
                return
        }

        for _, v := range shorts {
                bytes[0] = byte(v >> 8)
                bytes[1] = byte(v & 255)

                _, err = conn.Write(bytes[0:])
                if err != nil {
                        return
                }
        }
}

func checkError(err error) {
        if err != nil {
                fmt.Println("Fatal error ", err.Error())
                os.Exit(1)
        }
}

```

而读取字节流、提取并检查 BOM，然后解码流的其余部分的客户端是`UTF16Client.go`:

```go
/* UTF16 Client
 */
package main

import (
        "fmt"
        "net"
        "os"
        "unicode/utf16"
)

const BOM = '\ufffe'

func main() {
        if len(os.Args) != 2 {
                fmt.Println("Usage: ", os.Args[0], "host:port")
                os.Exit(1)
        }
        service := os.Args[1]

        conn, err := net.Dial("tcp", service)
        checkError(err)

        shorts := readShorts(conn)
        ints := utf16.Decode(shorts)
        str := string(ints)

        fmt.Println(str)

        os.Exit(0)
}

func readShorts(conn net.Conn) []uint16 {
        var buf [512]byte

        // read everything into the buffer
        n, err := conn.Read(buf[0:2])
        for true {
                m, err := conn.Read(buf[n:])
                if m == 0 || err != nil {
                        break
                }
                n += m
        }

        checkError(err)
        var shorts []uint16
        shorts = make([]uint16, n/2)

        if buf[0] == 0xff && buf[1] == 0xfe {
                // big endian
                for i := 2; i < n; i += 2 {
                        shorts[i/2] = uint16(buf[i])<<8 + uint16(buf[i+1])
                }
        } else if buf[1] == 0xff && buf[0] == 0xfe {
                // little endian
                for i := 2; i < n; i += 2 {
                        shorts[i/2] = uint16(buf[i+1])<<8 + uint16(buf[i])
                }
        } else {
                // unknown byte order
                fmt.Println("Unknown order")
        }
        return shorts

}

func checkError(err error) {
        if err != nil {
                fmt.Println("Fatal error ", err.Error())
                os.Exit(1)
        }
}

```

客户端打印服务器发送的`"j'ai arrÃªtÃ©"`。

## Unicode 哥特式

这本书不是关于 i18n 问题的。特别是，我们不想深究 Unicode 的神秘领域。但是你应该知道 Unicode 不是一个简单的编码，有很多复杂的地方。例如，一些早期的字符集使用非空格字符，尤其是重音字符。这是 Unicode 中引入的，因此您可以用两种方式生成重音字符:作为单个 Unicode 字符，或者作为一对非空格重音加非重音字符。例如 U+04D6，“西里尔文大写字母 ie 带短音符”是单个字符，。相当于 U+0415，“西里尔文大写字母 ie”结合短音符 U+0306“结合短音符”。这使得字符串比较有时很困难。这可能是一些非常难以理解的错误的原因。

Go 实验树中有一个叫`golang.org/x/text/unicode/norm`的包，可以规格化 Unicode 字符串。它可以安装到您的 Go 软件包树中:

```go
go get golang.org/x/text/unicode/norm

```

请注意，它是“子库”Go 项目树中的一个包，可能不稳定。

实际上有四种标准的 Unicode 形式。最常见的是 NFC。一个字符串可以通过`norm.NFC.String(str)`转换成 NFC 形式。下面这个名为`norm.go`的程序以两种方式形成![A436770_1_En_6_Figb_HTML.gif](img/A436770_1_En_6_Figb_HTML.gif)的字符串，一种是单个字符，另一种是组合字符，并打印字符串、它们的字节，然后是规范化形式及其字节。

```go
package main

import (
        "fmt"
        "golang.org/x/text/unicode/norm"
)

func main() {
        str1 := "\u04d6"
        str2 := "\u0415\u0306"
        norm_str2 := norm.NFC.String(str2)
        bytes1 := []byte(str1)
        bytes2 := []byte(str2)
        norm_bytes2 := []byte(norm_str2)

        fmt.Println("Single char ", str1, " bytes ", bytes1)
        fmt.Println("Composed char ", str2, " bytes ", bytes2)
        fmt.Println("Normalized char", norm_str2, " bytes ", norm_bytes2)
}

```

以下是输出:

`Single char`![A436770_1_En_6_Figa_HTML.gif](img/A436770_1_En_6_Figa_HTML.gif)`bytes`T2】

`Composed char`![A436770_1_En_6_Figa_HTML.gif](img/A436770_1_En_6_Figa_HTML.gif)`bytes`T2】

`Normalized char`![A436770_1_En_6_Figa_HTML.gif](img/A436770_1_En_6_Figa_HTML.gif)`bytes`T2】

## ISO 8859 和 Go

ISO 8859 系列是 8 位字符集，适用于欧洲的不同地区和其他一些地区。它们在底部都有相同的 ASCII 集，但在顶部有所不同。据谷歌称，ISO 8859 代码约占其所见网页的 20%，但现在这一比例已经下降。

第一个代码是 ISO 8859-1 或 Latin-1，其前 256 个字符与 Unicode 相同。Latin-1 字符的编码值在 UTF-16 和默认的 ISO 8859-1 编码中是相同的。但这实际上没有多大帮助，因为 UTF-16 是 16 位编码，而 ISO 8859-1 是 8 位编码。UTF-8 是一种 8 位编码，但它使用最高位来表示额外的字节，因此 UTF-8 和 ISO 8859-1 只有 ASCII 子集重叠。所以 UTF-8 也帮不上什么忙。

但是 ISO 8859 系列没有任何复杂的问题。每个字符集中的每个字符对应一个唯一的 Unicode 字符。例如，在 ISO 8859-2，字符“带 ogonek 的拉丁文大写字母 I”具有 ISO 8859-2 码位 0xc7(十六进制)和相应的 Unicode 码位 U+012E。ISO 8859 集和相应的 Unicode 字符之间的转换本质上只是一个查找表的过程。

从 ISO 8859 码点到 Unicode 码点的表可以作为 256 个整数的数组来完成。但是其中许多将具有与索引相同的值。所以我们只是使用一个不同的映射，那些不在映射中的就取索引值。

ISO 8859-2 地图的一部分如下:

```go
var unicodeToISOMap = map[int] uint8 {
    0x12e: 0xc7,
    0x10c: 0xc8,
    0x118: 0xca,
    // plus more
}

```

将 UTF-8 字符串转换为 ISO 8859-2 字节数组的函数如下:

```go
/* Turn a UTF-8 string into an ISO 8859 encoded byte array
*/
func unicodeStrToISO(str string) []byte {
        // get the unicode code points
        codePoints := []int(str)

        // create a byte array of the same length
        bytes := make([]byte, len(codePoints))

        for n, v := range(codePoints) {
                // see if the point is in the exception map
                iso, ok := unicodeToISOMap[v]
                if !ok {
                        // just use the value
                        iso = uint8(v)
                }
                bytes[n] = iso
        }
        return bytes
}

```

以类似的方式，您可以将 ISO 8859-2 字节数组更改为 UTF-8 字符串:

```go
var isoToUnicodeMap = map[uint8] int {
    0xc7: 0x12e,
    0xc8: 0x10c,
    0xca: 0x118,
    // and more
}

func isoBytesToUnicode(bytes []byte) string {
        codePoints := make([]int, len(bytes))
        for n, v := range(bytes) {
                unicode, ok :=isoToUnicodeMap[v]
                if !ok {
                        unicode = int(v)
                }
                codePoints[n] = unicode
        }
        return string(codePoints)
}

```

这些函数可以用来读写 ISO 8859-2 字节形式的 UTF-8 字符串。通过改变映射表，可以覆盖其他 ISO 8859 码。Latin-1，或 ISO 8859-1，是一个特例—异常映射为空，因为 Latin-1 的代码点在 Unicode 中是相同的。您也可以对基于表映射的其他字符集使用相同的技术，比如 Windows 1252。

## 其他字符集和 Go

有非常多的字符集编码。根据谷歌的说法，这些通常只在网络文档中有很小的用途，随着时间的推移，有望进一步减少。但是如果你的软件想要占领所有的市场，那么你可能需要处理它们。

在最简单的情况下，查找表就足够了。但这并不总是奏效。字符编码 ISO 2022 通过使用有限状态机交换代码页来最小化字符集的大小。这是借用了一些日本编码，使事情变得非常复杂。

Go 目前只对“子库”包树中的其他字符集提供包支持。例如，包`golang.org/x/text/encoding/japanese`处理 EUC-JP 和 Shift JIS。

## 结论

这一章没有太多代码。相反，出现了一些非常复杂领域的概念。这取决于你:如果你想假设每个人都说美国英语，那么这个世界很简单。但是，如果您希望您的应用程序可供世界其他地方使用，您需要注意这些复杂性。